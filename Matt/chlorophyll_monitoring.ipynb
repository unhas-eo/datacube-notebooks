{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNHAS: Monitoring chlorophyll-<i>a</i> in waterbodies\n",
    "\n",
    "**Contents**\n",
    "\n",
    "  - [Overview](#Overview)\n",
    "    - [Sentinel-2 use case](#Sentinel-2-use-case)\n",
    "    - [Description](#Description)\n",
    "  - [Notebook setup](#Notebook-setup)\n",
    "    - [Dask](#Dask)\n",
    "  - [Region of interest](#Region-of-interest)\n",
    "    - [Analysis parameters](#Analysis-parameters)\n",
    "    - [Selected location display](#Selected-location-display)\n",
    "  - [Sentinel-2 dataset](#Sentinel-2-dataset)\n",
    "    - [Loading the data](#Loading-the-data)\n",
    "    - [Visualise the data](#Visualise-the-data)\n",
    "    - [Band indices](#Band-indices)\n",
    "      - [Band arithmetic](#Band-arithmetic)\n",
    "      - [Computation](#Computation)\n",
    "  - [Summary plot](#Summary-plot)\n",
    "    - [Analysis constants](#Analysis-constants)\n",
    "    - [Total water area](#Total-water-area)\n",
    "    - [Average NDCI](#Average-NDCI)\n",
    "    - [Combined indices plot](#Combined-indices-plot)\n",
    "  - [Spatial plots](#Spatial-plots)\n",
    "    - [NDCI plots](#NDCI-plots)\n",
    "    - [True colour display](#True-colour-display)\n",
    "\n",
    "# Overview\n",
    "\n",
    "Inland waterbodies are essential for supporting human life, both through the supply of drinking water and the support of agriculture and aquaculture.\n",
    "Such waterbodies can be contaminated by outbreaks of blue-green (and other toxic) algae, causing health issues for people and animals.\n",
    "For example, up to a million fish died during an [algal bloom event](https://www.abc.net.au/news/2019-01-08/second-fish-kill-in-darling-river-at-menindee/10696632) in the Darling river in late 2018 and early 2019. \n",
    "While the health of waterbodies can be monitored from the ground through sampling, satellite imagery can complement this, potentially improving the detection of large algal bloom events.\n",
    "However, there needs to be a well-understood and tested way to link satellite observations to the presence of algal blooms.\n",
    "\n",
    "## Sentinel-2 use case\n",
    "\n",
    "Algal blooms are associated with the presence of clorophyll-*a* in waterbodies.\n",
    "[Mishra and Mishra (2012)](https://doi.org/10.1016/j.rse.2011.10.016) developed the normalised difference chlorophyll index (NDCI), which serves as a qualitative indicator for the concentration of chlorophyll-*a* on the surface of a waterbody.\n",
    "The index requires information from a specific part of the infrared specturm, known as the 'red edge'. \n",
    "This is captured as part of Sentinel-2's spectral bands, making it possible to measure the NDCI with Sentinel-2. \n",
    "\n",
    "On the other hand, the following caveats should also be kept in mind:\n",
    "\n",
    "* The NDCI is currently treated as an experimental index for Australia, as futher work is needed to calibrate and validate how well the index relates to the presence of chlorophyll-*a*. \n",
    "* It is also important to remember that algal blooms will usually result in increased values of the NDCI, but not all NDCI increases will be from algal blooms. For example, there may be seasonal fluctuations in the amount of chlorophyll-*a* in a waterbody.\n",
    "* Further validation work is required to understand how shallow water and atmospheric effects affect the NDCI, and its use in identifying high concentrations of chlorophyll-*a*.\n",
    "\n",
    "## Description\n",
    "\n",
    "In this example, we measure the NDCI for Lake Cawndilla, one of the Menindee Lakes in south-west New South Wales (on the Darling River), which was strongly affected by the algal bloom event mentioned above. This is combined with information about the size of the waterbody, which is used to build a helpful visualisation of how the water level and presence of chlorophyll-*a* changes over time. The worked example takes users through the code required to:\n",
    "\n",
    "1. load cloud-free Sentinel-2 images for the area of interest\n",
    "2. compute indices to measure the presence of water and chlorophyll-*a*\n",
    "3. generate informative visualisations to identify the presence of chlorophyll-*a*.\n",
    "\n",
    "This notebook is adapted from a [Digital Earth Australia](https://github.com/GeoscienceAustralia/dea-notebooks) example.\n",
    "\n",
    "**A note regarding compatibility**\n",
    "\n",
    "As stated above, this notebook makes use of a specific dataset of remote sensing data, and is applied over a given region of interest. The code below will thus not run properly if the EASI deployment used to run this notebook does not also contain a similar dataset.\n",
    "\n",
    "Users can nonetheless investigate the outputs provided in this demonstration notebook, and also potentially modify certain variables in the code below to allow the notebook to run with a different EASI deployment (e.g. different remote sensing data, region of interest, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook setup\n",
    "\n",
    "Here, we load the key Python packages and supporting functions for the subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### System\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "### Datacube \n",
    "import datacube\n",
    "from datacube.utils import masking\n",
    "from odc.algo import enum_to_bool\n",
    "\n",
    "### Data tools\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "### Plotting\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### EASI tools\n",
    "sys.path.append('../scripts')\n",
    "from app_utils import display_map\n",
    "from notebook_utils import initialize_dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's now connect to the datacube database, which provides functionality for loading and displaying stored Earth observation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app=\"Chlorophyll_monitoring\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask\n",
    "\n",
    "Rather than loading the Sentinel-2 data into the system memory, this notebook will make use of Dask to load up and process the dataset.\n",
    "\n",
    "Dask is a Python library for distributed (parallel) processing, which allows us to work on very large array or datacube objects that would otherwise not fit in the memory of any single compute node. Dask relies on the creation of a Dask Gateway (or local) cluster with associated scheduler, which is done in the following cell through the `initialize_dask` helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster, client = initialize_dask(use_gateway=True, workers=2, wait=True)\n",
    "display(client)\n",
    "display(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Dashboard` link provided above (`Client` section) can be used to monitor the status of the Dask cluster and associated processing tasks during the execution of various cells in the rest of this notebook.\n",
    "\n",
    "# Region of interest\n",
    "\n",
    "## Analysis parameters\n",
    "\n",
    "The following cell sets the analysis parameters, which define the area of interest and the length of time to conduct the analysis over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Area of interest (Lake Cawndilla)\n",
    "latitude = (-32.423, -32.523)\n",
    "longitude = (142.180, 142.280)\n",
    "\n",
    "### Range of dates for the analysis\n",
    "time = (\"2017-06-01\", \"2019-06-01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected location display\n",
    "\n",
    "The next cell will display the selected area on an interactive map. Feel free to zoom in and out to get a better understanding of the area you'll be analysing. Clicking on any point of the map will reveal the latitude and longitude coordinates of that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_map(x=longitude, y=latitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentinel-2 dataset\n",
    "\n",
    "## Loading the data\n",
    "\n",
    "The first step in the analysis is to load Sentinel-2 data for the specified area of interest and time range. We also specifically select various spectral bands to load: the `red`, `green` and `blue` bands will allow for true-colour displays of the Sentinel-2 data, while other bands will be used for the calculation of water-related indices further below. In addition, the pixel QA band `fmask` will be used to mask out the pixels affected by clounds, shadows, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Satellite products to load\n",
    "products = [\"s2a_ard_granule\", \"s2b_ard_granule\"]\n",
    "\n",
    "### Datacube load query\n",
    "query = { \"x\": longitude,\n",
    "          \"y\": latitude,\n",
    "          \"time\": time,\n",
    "          \"measurements\": [ \"nbart_red_edge_1\",  # Red edge 1 band\n",
    "                            \"nbart_red\",         # Red band\n",
    "                            \"nbart_green\",       # Green band\n",
    "                            \"nbart_blue\",        # Blue band\n",
    "                            \"nbart_swir_2\",      # Short-wave infrared band\n",
    "                            \"fmask\" ],           # Pixel QA band\n",
    "          \"output_crs\": \"EPSG:3577\",\n",
    "          \"resolution\": (-20, 20) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to load data from two or more satellite sensors into the same time series, as done here with Sentinel-2A and Sentinel-2B, we can first determine the `datasets` available for each satellite sensor over the (temporal and spatial) region of interest. Subsequently, we use `dc.load()` to load up these datasets (instead of the usual `product` argument), which automatically combines and sorts all images from the selected sensors into a single, consistent time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = []\n",
    "for product in products:\n",
    "    datasets = dc.find_datasets(product=product, **query )\n",
    "    dataset_list.extend(datasets)\n",
    "\n",
    "ds_s2 = dc.load(datasets=dataset_list, **query, dask_chunks={\"y\":2048, \"x\":2048})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will mask out any clouds (and other pixel QA issues) in the dataset, and also filter out any image where less than 70% of the pixels are classified as clear observations. Note here that we're including `snow` pixels in the dataset of \"good\" pixels &ndash; quite a few pixels in the time series are identified as being `snow`, but snow cover is highly improbable at the selected location. Instead, these `snow` pixels are very likely to actually represent clear observations that are mis-classified, which is likely to occur in salt lake regions with highly reflective land covers. Rather than removing these likely mis-classified pixels, we thus include them in the set of clear observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_gooddata = 0.7   # percentage threshold\n",
    "\n",
    "### Mask of valid pixels\n",
    "good_pixel_flags = {'valid', 'water', 'snow'}   # pixels to retain (i.e. remove pixels flagged as 'nodata', 'cloud', 'shadow')\n",
    "good_pixel_mask = enum_to_bool(ds_s2['fmask'], good_pixel_flags)\n",
    "good_pixel_mask = good_pixel_mask.persist()\n",
    "\n",
    "### Percentage of good data for each time slice\n",
    "data_perc = good_pixel_mask.sum(axis=[1,2]) / (good_pixel_mask.shape[1]*good_pixel_mask.shape[2])\n",
    "keep = (data_perc>=min_gooddata).persist()\n",
    "\n",
    "### Drop low quality time slices\n",
    "total_obs = len(ds_s2.time)\n",
    "ds_s2 = ds_s2.sel(time=keep)\n",
    "good_pixel_mask = good_pixel_mask.sel(time=keep)\n",
    "\n",
    "print(f'Filtered the time series to {len(ds_s2.time)} (out of {total_obs}) '\n",
    "      f'time steps with at least {min_gooddata:.1%} good quality pixels.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can apply the resulting 'good pixel' mask to the data, as well as a further 'no-data' mask and further scaling operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Valid mask (i.e. not 'nodata'), for each data layer\n",
    "valid_mask = masking.valid_data_mask(ds_s2)\n",
    "\n",
    "### Scaling factors for Sentinel-2 data (GA S2 products)\n",
    "scale = 0.0001  # divide by 10000\n",
    "offset = 0.0\n",
    "\n",
    "### Apply valid mask, good pixel mask, and scaling to each layer\n",
    "ds_s2['nbart_red_edge_1'] = ds_s2['nbart_red_edge_1'].where(valid_mask['nbart_red_edge_1'] & good_pixel_mask) * scale + offset\n",
    "ds_s2['nbart_red'] =        ds_s2['nbart_red'].where(valid_mask['nbart_red'] & good_pixel_mask)               * scale + offset\n",
    "ds_s2['nbart_green'] =      ds_s2['nbart_green'].where(valid_mask['nbart_green'] & good_pixel_mask)           * scale + offset\n",
    "ds_s2['nbart_blue'] =       ds_s2['nbart_blue'].where(valid_mask['nbart_blue'] & good_pixel_mask)             * scale + offset\n",
    "ds_s2['nbart_swir_2'] =     ds_s2['nbart_swir_2'].where(valid_mask['nbart_swir_2'] & good_pixel_mask)         * scale + offset\n",
    "ds_s2 = ds_s2.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the processing is complete, we can examine the data as done in the next cell. The `Dimensions` argument reveals the number of time steps in the dataset, as well as the number of pixels in the `x` (longitude) and `y` (latitude) dimensions. Clicking on the `data repr` icon for each of the `Data variables` also confirms that the data is currently loaded as Dask chunks on the Dask cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the data\n",
    "\n",
    "We can visualise the data using a true-colour image display for a number of time steps. White areas indicate where clouds or other invalid pixels in the image have been masked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.linspace(1, ds_s2.sizes['time'], 3, dtype='int') - 1   # select some time slices to display\n",
    "\n",
    "### Plot the selected time slices (true-colour display)\n",
    "image_array = ds_s2[['nbart_red', 'nbart_green', 'nbart_blue']].isel(time=tmp).to_array()\n",
    "image_array.plot.imshow(robust=True, col='time', col_wrap=3, size=6, aspect=ds_s2.x.shape[0]/ds_s2.y.shape[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Band indices\n",
    "\n",
    "### Band arithmetic\n",
    "\n",
    "This study measures the presence of water through the modified normalised difference water index (MNDWI), while the amount of clorophyll-*a* is calculated using the normalised difference clorophyll index (NDCI).\n",
    "\n",
    "MNDWI is calculated from the `green` and shortwave infrared (`SWIR`) bands to identify water.\n",
    "The formula is\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{MNDWI} = \\frac{\\text{Green} - \\text{SWIR}}{\\text{Green} + \\text{SWIR}}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "When interpreting this index, values greater than 0 indicate water.\n",
    "\n",
    "NDCI is calculated from the `red edge 1` and `red` bands to identify water.\n",
    "The formula is\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{NDCI} = \\frac{\\text{Red_edge_1} - \\text{Red}}{\\text{Red_edge_1} + \\text{Red}}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "When interpreting this index, higher values indicate a higher concentration of clorophyll-*a*.\n",
    "\n",
    "### Computation\n",
    "\n",
    "As per the formulae provided above, we can now calculate the relevant indices from the various bands in our dataset. The code below achieves this, and subsequently saves the results back as new layers in the `ds_s2` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MNDWI\n",
    "ds_s2['MNDWI'] = ( (ds_s2.nbart_green - ds_s2.nbart_swir_2) /\n",
    "                   (ds_s2.nbart_green + ds_s2.nbart_swir_2) )\n",
    "\n",
    "### NDCI\n",
    "ds_s2['NDCI'] = ( (ds_s2.nbart_red_edge_1 - ds_s2.nbart_red) /\n",
    "                  (ds_s2.nbart_red_edge_1 + ds_s2.nbart_red) )\n",
    "\n",
    "ds_s2 = ds_s2.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNDWI and NDCI values should now appear as data variables, along with the loaded measurements, in the `ds_s2` data set. We can check this by printing the data set below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary plot\n",
    "\n",
    "To get an understanding of how the waterbody has changed over time, the following section builds a plot that uses the MNDWI to measure (roughly) the area of the waterbody, along with the NDCI to track how the concentration of clorophyll-*a* is changing over time. This could be used to quickly assess the status of a given waterbody."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis constants\n",
    "\n",
    "If the pixel area is known, the number of pixels classified as water (i.e, where MNDWI > 0) can be used as a proxy for the area of the waterbody. The following cell generates the necessary constants for performing this conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_length = query[\"resolution\"][1]   # in metres\n",
    "m_per_km = 1000   # conversion from metres to kilometres\n",
    "\n",
    "area_per_pixel = pixel_length**2 / m_per_km**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total water area\n",
    "\n",
    "The next cell starts by filtering the dataset to only keep the pixels that are classified as water. It then calculates the water area by counting all the MNDWI pixels in the filtered data set, calculating a rolling median &ndash; this helps smooth the results to account for variation from cloud-masking. This median count is then multiplied by the area-per-pixel value to obtain an estimate of the water area over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Water pixels\n",
    "ds_s2_water = ds_s2.where(ds_s2.MNDWI>0.0)\n",
    "ds_s2_watercount = ds_s2_water.MNDWI.count(dim=[\"x\", \"y\"])\n",
    "\n",
    "### Total water area\n",
    "waterarea = ds_s2_watercount.rolling(time=3, center=True, min_periods=1).median(skipna=True)\n",
    "waterarea = waterarea * area_per_pixel\n",
    "waterarea = waterarea.persist()   # trigger the computation on the Dask workers\n",
    "\n",
    "### Plot\n",
    "fig, axes = plt.subplots(1, 1, figsize=(12, 4))\n",
    "waterarea.plot()\n",
    "axes.set_xlabel(\"Date\")\n",
    "axes.set_ylabel(\"Waterbody area (km$^2$)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average NDCI\n",
    "\n",
    "The next cell computes the average NDCI for each time step using the filtered data set. This means that we're only tracking the NDCI in waterbody areas, and not on land.\n",
    "\n",
    "To make the summary plot, we calculate NDCI across all pixels; this allows us to track overall changes in NDCI, but doesn't tell us where the increase occured within the waterbody (this is covered in the next section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Average NDCI\n",
    "average_ndci = ds_s2_water.NDCI.mean(dim=[\"x\", \"y\"], skipna=True)\n",
    "average_ndci = average_ndci.persist()   # trigger the computation on the Dask workers\n",
    "\n",
    "### Plot\n",
    "fig, axes = plt.subplots(1, 1, figsize=(12, 4))\n",
    "average_ndci.plot()\n",
    "axes.set_xlabel(\"Date\")\n",
    "axes.set_ylabel(\"Average NDCI\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined indices plot\n",
    "\n",
    "The cell below combines the total water area and average NDCI time series we generated above into a single summary plot. Notice that Python can be used to build highly-customised plots such as the stripe plot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(16, 5))\n",
    "\n",
    "### Colour map and normalisation\n",
    "# NDCI is plotted on a scale of -0.1 to 0.3, so normalise the colour map accordingly\n",
    "min_ndci_scale = -0.1\n",
    "max_ndci_scale = 0.3\n",
    "cmap = plt.get_cmap(\"viridis\")\n",
    "normal = plt.Normalize(vmin=min_ndci_scale, vmax=max_ndci_scale)\n",
    "\n",
    "### Store dataset dates as numbers (for ease of plotting)\n",
    "dates = matplotlib.dates.date2num(ds_s2_water.time.values)\n",
    "\n",
    "### Waterbody area line\n",
    "axes.plot_date(x=dates, y=waterarea, color=\"black\", linestyle=\"-\", marker=\"\")\n",
    "\n",
    "### NDCI as filled stripes\n",
    "# Fill in the plot by looping over the possible threshold values and filling\n",
    "# the areas that are greater than the threshold\n",
    "color_vals = np.linspace(0, 1, 100)\n",
    "threshold_vals = np.linspace(min_ndci_scale, max_ndci_scale, 100)\n",
    "for ii,thresh in enumerate(threshold_vals):\n",
    "    im = axes.fill_between( dates, 0, waterarea, where=(average_ndci>=thresh),\n",
    "                            norm=normal, facecolor=cmap(color_vals[ii]), alpha=1 )\n",
    "\n",
    "### Colour bar\n",
    "cax, _ = matplotlib.colorbar.make_axes(axes)\n",
    "cb2 = matplotlib.colorbar.ColorbarBase(cax, cmap=cmap, norm=normal)\n",
    "cb2.set_label(\"NDCI\")\n",
    "\n",
    "### Titles and labels\n",
    "axes.set_xlabel(\"Date\")\n",
    "axes.set_ylabel(\"Waterbody area (km$^2$)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial plots\n",
    "\n",
    "## NDCI plots\n",
    "\n",
    "While the summary plot above is useful at a glance, it can be interesting to see the full spatial picture at times where the NDCI is especially low or high. In the cell below, we first identify the time indices corresponding to the minimum and maximum NDCI values in the time series. We can then use these time indices to extract and plot the data of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndci_dates = ds_s2.time.values\n",
    "min_ndci_date = ndci_dates[ np.nanargmin(average_ndci.values) ]\n",
    "max_ndci_date = ndci_dates[ np.nanargmax(average_ndci.values) ]\n",
    "\n",
    "# Selected dates as Xarray data array (to select dates from the dataset)\n",
    "time_xr = xr.DataArray([min_ndci_date, max_ndci_date], dims=[\"time\"])\n",
    "\n",
    "### NDCI plots\n",
    "ds_s2_water.NDCI.sel(time=time_xr).plot.imshow( \"x\", \"y\", col=\"time\", cmap=cmap,\n",
    "                                                vmin=min_ndci_scale, vmax=max_ndci_scale,\n",
    "                                                col_wrap=2, robust=True, figsize=(12, 5) );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could also manually select two specific dates to display. The code below defines two useful functions: `closest_date` will find the date in a list of dates closest to any given date, and `date_index` will return the position of a particular date in a list of dates. These functions are useful for selecting images to compare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_date(list_of_dates, desired_date):\n",
    "    return min( list_of_dates, key=lambda x: abs(x-np.datetime64(desired_date)) )\n",
    "\n",
    "def date_index(list_of_dates, known_date):\n",
    "    return (np.where(list_of_dates == known_date)[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to define and plot two dates to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dates to view\n",
    "date_1 = \"2017-02-15\"\n",
    "date_2 = \"2018-11-15\"\n",
    "\n",
    "### Closest date available\n",
    "closest_date_1 = closest_date(ds_s2.time.values, date_1)\n",
    "closest_date_2 = closest_date(ds_s2.time.values, date_2)\n",
    "\n",
    "# Selected dates as Xarray data array (to select dates from the dataset)\n",
    "time_xr = xr.DataArray([closest_date_1, closest_date_2], dims=[\"time\"])\n",
    "\n",
    "### NDCI plots\n",
    "ds_s2_water.NDCI.sel(time=time_xr).plot.imshow( \"x\", \"y\", col=\"time\", cmap=cmap,\n",
    "                                                vmin=min_ndci_scale, vmax=max_ndci_scale,\n",
    "                                                col_wrap=2, robust=True, figsize=(12, 5) );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True colour display\n",
    "\n",
    "And finally, the cell below displays the true-colour images for the selected dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Index of closest dates\n",
    "closest_date_1_idx = date_index(ds_s2.time.values, closest_date_1)\n",
    "closest_date_2_idx = date_index(ds_s2.time.values, closest_date_2)\n",
    "\n",
    "### True colour plots\n",
    "image_array = ds_s2[['nbart_red', 'nbart_green', 'nbart_blue']].isel(time=[closest_date_1_idx, closest_date_2_idx]).to_array()\n",
    "image_array.plot.imshow(robust=True, col='time', col_wrap=3, size=6, aspect=ds_s2.x.shape[0]/ds_s2.y.shape[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### End notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
